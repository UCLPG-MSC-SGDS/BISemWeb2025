[
  {
    "objectID": "03-introduction_to_tmap.html",
    "href": "03-introduction_to_tmap.html",
    "title": "Day 1: Basic Mapping in R",
    "section": "",
    "text": "The goal for this session is to get you started with using RStudio, and being familiar with its environment. The session aims to introduce you to the basic programming etiquette, as well as building confidence for using RStudio as a GIS tool. At the end of this session, you should be able to perform some basic data managing tasks as well as generate a choropleth map in RStudio.\n\n\nThe first task includes becoming familiar with its environment and panels. We will begin a soft introduction on the basics of managing data in RStudio. This includes learning how to create various objects in RStudio such as vector and data frame objects. The crucial part of this session we be to know how to the set working directories as well as import your dataset in RStudio. Finally, we will learn how to perform the basic visualisation of spatial data in RStudio.\nLet us begin.\n\n\n\nYou should by now have opened RStudio on your laptop. When opening RStudio for the first time, you are greeted with its interface. The window is split into three panels: 1.) R Console, 2.) Environments and 3.) Files, help & Output.\n\n\n\n\n\n\n\n\n\n\nPanel 1: The Console lets the user type in R-codes to perform quick commands and basic calculations.\nPanel 2: The Environments lets the user see which datasets, spatial objects and other files are currently stored in RStudio’s memory\nPanel 3: Under the File tab, it lets the user access other folders stored in the computer to open datasets. Under the Help tab, it also allows the user to view the help menu for codes and commands. Finally, under the Plots tab, the user can perusal his/her generated plots (e.g., histogram, scatterplot, maps etc.).\n\nThe above section is the Menu Bar. You can access other functions for saving, editing, and opening a new Script File for writing codes. Opening a new Script File will reveal a fourth panel above the Console.\nYou can open a Script File by:\n\nClicking on the File tab listed inside the Menu Bar. A scroll down bar will reveal itself. Here, you can scroll to the section that says New File.\nUnder New File, click on R Script. This should open a new Script File titled “Untitled 1”.\n\n\n\n\nThe R console window (i.e., Panel 1) is the place where RStudio is waiting for you to tell it what to do. It will show the code you have commanded RStudio to execute, and it will also show the results from that command. You can type the commands directly into the window for execution as well.\nLet us start by using the console window as a basic calculator for typing in addition (+), subtraction (-), multiplication (*), division (/), exponents (^) and performing other complex sums.\nClick inside the R Console window and type 19+8, and press enter key button ↵ to get your answer. Quickly perform the following maths by typing them inside the R Console window:\n\n# Perform addition\n19+8\n\n# Perform subtraction\n20-89\n\n# Perform multiplication\n18*20\n\n# Perform division\n27/3\n\n# To number to a power e.g., 2 raise to the power of 8\n2^8\n\n# Perform complex sums\n(5*(170-3.405)/91)+1002\n\nAside from basic arithmetic operations, we can use some basic mathematical functions such as the exponential and logarithms:\n\nexp() is the exponential function\nlog() is the logarithmic function\n\nThese are quite useful functions for transforming or for standardising variables. You can perform the following execution of exp() and log() by typing them inside the R Console window:\n\n# use exp() to apply an exponential to a value\nexp(5) \n\n# use log() to transforrm a value on to a logarithm scale\nlog(3)\n\n\n\n\nNow that we are familiar with using the console as a calculator. Let us build from this and learn one of the most important codes in R programming called the Assignment Operator.\nThis arrow symbol &lt;- is called the Assignment Operator. It is typed by pressing the less than symbol key &lt; followed by the hyphen symbol key -. It allows the user to assign values or entire data structure(s) to an Object.\nObjects are defined as stored quantities in RStudio’s environment. These objects can be assigned anything from numeric values to character string values. For instance, say we want to create a numeric object called x and assign it with a value of 3. We do this by typing x &lt;- 3. When you enter the object x in the console and press enter ↵, it will return the numeric value 3.\nAnother example, suppose we want to create a string object called y and assign it with some text \"Hello!\". We do this typing y &lt;- \"Hello!\". When you enter y in console, it will return the text value Hello.\nLet us create the objects a,b, c, and d and assign them with numeric values. Perform the following by typing them inside the R Console window:\n\n# Create an object called 'a' and assign the value 17 to it\na &lt;- 17\n# Type the object 'a' in console as a command to return value 17\na\n\n# Create an object called 'b' and assign the value 10 to it\nb &lt;- 10\n# Type the object 'b' in console as a command to return value 10\nb\n\n# Create an object called 'c' and assign the value 9 to it\nc &lt;- 9\n# Type the object 'c' in console as a command to return value 9\nc\n\n# Create an object called 'd' and assign the value 8 to it\nd &lt;- 8\n# Type the object 'd' in console as a command to return value 8\nd\n\nNotice how the objects a, b, c and d and its value are stored in RStudio’s environment panel. We can perform the following arithmetic operations with these object values:\n\n# type the following and return an answer\n(a + b + c + d)/5\n\n# type the following and return an answer\n(5*(a-c)/d)^2\n\nLet us create more objects but this time we will assign character string(s) to them. Please note that when typing a string of characters as data you will need to cover them with quotation marks \"...\". For example, say we want to create a string object called y and assign it with some text \"Hello!\". We do this by typing y &lt;- \"Hello!\".\nTry these examples of assigning the following character text to an object:\n\n# Create an object called 'e' and assign the character string \"RStudio\"\ne &lt;- \"RStudio\"\n# Type the object 'e' in the console as a command to return \"RStudio\"\ne\n\n# Create an object called 'f', assign character string \"Hello world\" \nf &lt;- \"Hello world\"\n\n# Type the object 'f' in the console as a command to return \"Hello world\"\nf\n\n# Create an object called 'g' and assign \"Blade Runner is amazing\"\ng &lt;- \"Blade Runner is amazing\"\n# Type the object 'g' in the console to return the result\ng\n\nWe are now familiar with using the console and assigning values (i.e., numeric and string values) to objects. The parts covered here are the initial steps and building blocks for coding and creating datasets in RStudio.\nLet us progress to the next section. Here is where the serious stuff start. We will learn the basics of managing data and some coding etiquette - this includes creating data frames, importing & exporting spreadsheets, setting up work directories, column manipulations and merging two data frames. Learning these basic tasks are key for managing data in R/RStudio.\n\n\n\n\n\n\nImportant\n\n\n\nPoint of no return: From here on out - let us open a script file and type codes there instead of the Console! We are getting serious now, we will never use the Console again.",
    "crumbs": [
      "Practical Sessions",
      "Day 1: Basic Mapping in R"
    ]
  },
  {
    "objectID": "03-introduction_to_tmap.html#introduction",
    "href": "03-introduction_to_tmap.html#introduction",
    "title": "Day 1: Basic Mapping in R",
    "section": "",
    "text": "The goal for this session is to get you started with using RStudio, and being familiar with its environment. The session aims to introduce you to the basic programming etiquette, as well as building confidence for using RStudio as a GIS tool. At the end of this session, you should be able to perform some basic data managing tasks as well as generate a choropleth map in RStudio.\n\n\nThe first task includes becoming familiar with its environment and panels. We will begin a soft introduction on the basics of managing data in RStudio. This includes learning how to create various objects in RStudio such as vector and data frame objects. The crucial part of this session we be to know how to the set working directories as well as import your dataset in RStudio. Finally, we will learn how to perform the basic visualisation of spatial data in RStudio.\nLet us begin.\n\n\n\nYou should by now have opened RStudio on your laptop. When opening RStudio for the first time, you are greeted with its interface. The window is split into three panels: 1.) R Console, 2.) Environments and 3.) Files, help & Output.\n\n\n\n\n\n\n\n\n\n\nPanel 1: The Console lets the user type in R-codes to perform quick commands and basic calculations.\nPanel 2: The Environments lets the user see which datasets, spatial objects and other files are currently stored in RStudio’s memory\nPanel 3: Under the File tab, it lets the user access other folders stored in the computer to open datasets. Under the Help tab, it also allows the user to view the help menu for codes and commands. Finally, under the Plots tab, the user can perusal his/her generated plots (e.g., histogram, scatterplot, maps etc.).\n\nThe above section is the Menu Bar. You can access other functions for saving, editing, and opening a new Script File for writing codes. Opening a new Script File will reveal a fourth panel above the Console.\nYou can open a Script File by:\n\nClicking on the File tab listed inside the Menu Bar. A scroll down bar will reveal itself. Here, you can scroll to the section that says New File.\nUnder New File, click on R Script. This should open a new Script File titled “Untitled 1”.\n\n\n\n\nThe R console window (i.e., Panel 1) is the place where RStudio is waiting for you to tell it what to do. It will show the code you have commanded RStudio to execute, and it will also show the results from that command. You can type the commands directly into the window for execution as well.\nLet us start by using the console window as a basic calculator for typing in addition (+), subtraction (-), multiplication (*), division (/), exponents (^) and performing other complex sums.\nClick inside the R Console window and type 19+8, and press enter key button ↵ to get your answer. Quickly perform the following maths by typing them inside the R Console window:\n\n# Perform addition\n19+8\n\n# Perform subtraction\n20-89\n\n# Perform multiplication\n18*20\n\n# Perform division\n27/3\n\n# To number to a power e.g., 2 raise to the power of 8\n2^8\n\n# Perform complex sums\n(5*(170-3.405)/91)+1002\n\nAside from basic arithmetic operations, we can use some basic mathematical functions such as the exponential and logarithms:\n\nexp() is the exponential function\nlog() is the logarithmic function\n\nThese are quite useful functions for transforming or for standardising variables. You can perform the following execution of exp() and log() by typing them inside the R Console window:\n\n# use exp() to apply an exponential to a value\nexp(5) \n\n# use log() to transforrm a value on to a logarithm scale\nlog(3)\n\n\n\n\nNow that we are familiar with using the console as a calculator. Let us build from this and learn one of the most important codes in R programming called the Assignment Operator.\nThis arrow symbol &lt;- is called the Assignment Operator. It is typed by pressing the less than symbol key &lt; followed by the hyphen symbol key -. It allows the user to assign values or entire data structure(s) to an Object.\nObjects are defined as stored quantities in RStudio’s environment. These objects can be assigned anything from numeric values to character string values. For instance, say we want to create a numeric object called x and assign it with a value of 3. We do this by typing x &lt;- 3. When you enter the object x in the console and press enter ↵, it will return the numeric value 3.\nAnother example, suppose we want to create a string object called y and assign it with some text \"Hello!\". We do this typing y &lt;- \"Hello!\". When you enter y in console, it will return the text value Hello.\nLet us create the objects a,b, c, and d and assign them with numeric values. Perform the following by typing them inside the R Console window:\n\n# Create an object called 'a' and assign the value 17 to it\na &lt;- 17\n# Type the object 'a' in console as a command to return value 17\na\n\n# Create an object called 'b' and assign the value 10 to it\nb &lt;- 10\n# Type the object 'b' in console as a command to return value 10\nb\n\n# Create an object called 'c' and assign the value 9 to it\nc &lt;- 9\n# Type the object 'c' in console as a command to return value 9\nc\n\n# Create an object called 'd' and assign the value 8 to it\nd &lt;- 8\n# Type the object 'd' in console as a command to return value 8\nd\n\nNotice how the objects a, b, c and d and its value are stored in RStudio’s environment panel. We can perform the following arithmetic operations with these object values:\n\n# type the following and return an answer\n(a + b + c + d)/5\n\n# type the following and return an answer\n(5*(a-c)/d)^2\n\nLet us create more objects but this time we will assign character string(s) to them. Please note that when typing a string of characters as data you will need to cover them with quotation marks \"...\". For example, say we want to create a string object called y and assign it with some text \"Hello!\". We do this by typing y &lt;- \"Hello!\".\nTry these examples of assigning the following character text to an object:\n\n# Create an object called 'e' and assign the character string \"RStudio\"\ne &lt;- \"RStudio\"\n# Type the object 'e' in the console as a command to return \"RStudio\"\ne\n\n# Create an object called 'f', assign character string \"Hello world\" \nf &lt;- \"Hello world\"\n\n# Type the object 'f' in the console as a command to return \"Hello world\"\nf\n\n# Create an object called 'g' and assign \"Blade Runner is amazing\"\ng &lt;- \"Blade Runner is amazing\"\n# Type the object 'g' in the console to return the result\ng\n\nWe are now familiar with using the console and assigning values (i.e., numeric and string values) to objects. The parts covered here are the initial steps and building blocks for coding and creating datasets in RStudio.\nLet us progress to the next section. Here is where the serious stuff start. We will learn the basics of managing data and some coding etiquette - this includes creating data frames, importing & exporting spreadsheets, setting up work directories, column manipulations and merging two data frames. Learning these basic tasks are key for managing data in R/RStudio.\n\n\n\n\n\n\nImportant\n\n\n\nPoint of no return: From here on out - let us open a script file and type codes there instead of the Console! We are getting serious now, we will never use the Console again.",
    "crumbs": [
      "Practical Sessions",
      "Day 1: Basic Mapping in R"
    ]
  },
  {
    "objectID": "03-introduction_to_tmap.html#basics-of-managing-data-in-rstudio",
    "href": "03-introduction_to_tmap.html#basics-of-managing-data-in-rstudio",
    "title": "Day 1: Basic Mapping in R",
    "section": "2 Basics of managing data in RStudio",
    "text": "2 Basics of managing data in RStudio\n\n2.1 How do we enter data into RStudio?\nAs you have already seen, RStudio is an object-oriented software package and so entering data is slightly different for the usual way of inputting information into a spreadsheet (e.g., Microsoft Excel). Here, you will need to enter the information as a Vector object before combining them into a Data Frame object.\nConsider this crude example of data containing the additional health information for 4 people. It contains the variable (or column) names ‘id’, ‘name’, ‘height’, ‘weight’ and ‘gender’\n\n\n\nid\nname\nheight\nweight\ngender\n\n\n\n\n1\nKofi\n1.65\n64.2\nM\n\n\n2\nHarry\n1.77\n80.3\nM\n\n\n3\nHuijun\n1.70\n58.7\nF\n\n\n4\nFatima\n1.68\n75.0\nF\n\n\n\nNow, when entering data to RStudio it is not like Microsoft Excel where we enter data into the cells of a spreadsheet. In RStudio, data is entered as a sequence of elements and listed inside an object called a vector. For instance, if we have three age values of 12, 57 and 26 years, and we want to enter this in RStudio, we need to use the combine function c() and combine these three elements into a vector object. Hence, the code will be c(12, 57, 26). We can assign this data by typing this code as age &lt;- c(12, 57, 26). Any time you type ‘age’ into RStudio console it will hence return these three values unless you chose to overwrite it with different information.\nLet us look at this more closely with the 'id' variable in the above data. Each person has an ID number from 1 to 4. We are going to list the numbers 1, 2, 3 and 4 as a sequence of elements into a vector using the combine function c() and then assign it to as a vector object calling it 'id'.\n\n# Create 'id' vector object \nid &lt;- c(1, 2, 3, 4)\n\n# Type the vector object 'id' in console to see output\nid\n\nNow, let us enter the information the same way for the remaining columns for ‘name’, ‘height’, ‘weight’ and ‘gender’ like we did for ‘id’:\n\n# Create 'name' vector object\nname &lt;- c(\"Kofi\", \"Harry\", \"Huijun\", \"Fatima\")\n\n# Create 'height' (in meters) vector object\nheight &lt;- c(1.65, 1.77, 1.70, 1.68)\n\n# Create 'weight' (in kg) vector object\nweight &lt;- c(64.2, 80.3, 58.7, 75.0)\n\n# Create 'gender' vector object\ngender &lt;- c(\"M\", \"M\", \"F\", \"F\")\n\nNow, that we have the vector objects ready. Let us bring them together to create a proper dataset. This new object is called a Data frame. We need to list the vectors inside the data.frame() function.\n\n# Create a dataset (data frame)\ndataset &lt;- data.frame(id, name, height, weight, gender)\n\n# Type the data frame object 'dataset' in console to see output\ndataset\n\n# You can also see dataset in a data viewer, type View() to data:\nView(dataset)\n\n\n\n\n\n\n\nNote\n\n\n\nThe column ‘id’ is a numeric variable with integers. The second column ‘name’ is a text variable with strings. The third & fourth columns ‘height’ and ‘weight’ are examples of numeric variables with real numbers with continuous measures. The variable ‘gender’ is a text variable with strings – however, this type of variable is classed as a categorical variable as individuals were categorised as either ‘M’ and ‘F’.\n\n\n\n\n2.2 How do we create a variable based on other existing variables in our data frame?\nTo access a variable by its name within a data frame, you will need to first type the name of the data frame followed by a $ (dollar sign), and then typing the variable’s name of interest. For instance, suppose you just want to see the height values in the Console viewer - you just type:\n\n# to access height - you need to type 'dataset$height'\ndataset$height\n\nWe can use other columns or variables within our data frame to create another variable. This technique is essentially important when cleaning and managing data. From this dataset, it is possible to derive the body mass index bmi from height and weight using the formula:\n\n\n\\(BMI = weight/height^2\\)\n\n\nTo generate bmi into our data frame, we would need to access the height (m) and weight (kg) columns using the $ from the data frame its stored to, and apply the above formula as a code to generate the new bmi column:\n\n# Create 'bmi' in the data frame i.e.,'dataset' and calculate 'bmi'\n# using the $weight and $height\ndataset$bmi &lt;- dataset$weight/((dataset$height)^2)\n# View the data frame ‘dataset’ and you will see the new bmi variable inside\nView(dataset)\n\nYou can overwrite the height (m) column to change its units into centimeters by multiplying it to 100; equally, the weight (kg) column can be overwritten and converted from units of kilograms to grams by multiplying it to 1000.\n\n# using $height and *100 \ndataset$height &lt;- dataset$height*100\n# using $weight and *100\ndataset$weight &lt;- dataset$weight*1000\n# use View() the data frame ‘dataset’ and you will see the updated variables\nView(dataset)\n\n\n\n2.3 How do we set the working directory in our computer by connecting our folder to RStudio with the setwd() function?\nNow, we are getting very serious here!\n\n\n\n\n\n\nImportant\n\n\n\nBefore we do anything - make sure to have downloaded the data set for this session if you haven’t done so by clicking here. In your computer, create a new folder on your desktop page and rename the folder to “BISemWeb2025”, and create another folder within “BISemWeb2025” and rename it as “Day 1”. Make sure to unzip and transfer ALL the downloaded data directly to the Day 1 folder.\n\n\nNow, this part of the practicals are probably the most important section of this tutorial. It’s usually the “make” or “break” phase (i.e., you will either end-up loving RStudio OR you will end-up hating it and not ever wanting to pick up R again!).\nWe are going to learn how to set-up a working directory. This basically refers to us connecting the RStudio software to the folder containing our dataset. It allows the user to tell RStudio to open data from a folder once it knows the path location. The path location specifies the whereabouts of the data file(s) stored within a computer. Setting your directory in RStudio beforehand makes life incredibly easier in terms of finding, importing, exporting and saving data in and out of RStudio.\nTo illustrate what a path location is – suppose on my desktop (mac/windows) there is a folder called “BISemWeb2025”, and within that folder, exists another folder called “Day 1”. Finally, suppose a comma separated value (.csv) data file called “CIV_Sub_Prefecture_Mosquito_Data.csv” is stored in it (i.e., Day 1). If via RStudio you want to open this CSV data file located in within the “Day 1” folder. You will need to first set the path to the “Day 1” folder in RStudio using the setwd() function.\nTherefore, the path location to this folder on a Windows machine would be written as follows, \"C:/Users/accountName/Desktop/BISemWeb2025/Day 1\". You can access this piece of information simply by:\n\nOpen the BISemWeb2025 folder to reveal the Day 1 folder.\nOpen the Day 1 folder in the data files are stored.\nNow, click on the bar at the top which shows BISemWeb2025 &gt; Day 1. This should highlight and show \"C:\\Users\\accountName\\Desktop\\BISemWeb2025\\Day 1\" (see image below):\n\n\n\n\n\n\n\n\n\n\n\nNow, copy \"C:\\Users\\accountName\\Desktop\\BISemWeb2025\\Day 1\" and paste the path name into the setwd() function in your R script.\nLastly, change all the back slashes \\ in the path name to forward slashes / and run the code. It should look like this: setwd(\"C:/Users/accountName/Desktop/BISemWeb2025/Day 1\").\n\nFor Windows, the setwd() is as follows:\n\n# set work directory in windows\nsetwd(\"C:/Users/accountName/Desktop/BISemWeb2025/Day 1\")\n\nFor MAC users, its marginally different. The path location would be written as follows, \"/Users/accountName/Desktop/BISemWeb2025/Day 1\". You can access this piece of information simply by:\n\nRight-clicking on the folder “Week 1” (not file) in which the files are stored.\nHold the “Option” ⌥ key down\n\n\n\n\n\n\n\n\n\n\n\nClick Copy \"filename\" as Pathname\nPaste the copied path name into the function setwd() and run the code\n\nFor Mac, the setwd() is as follows:\n\n# set work directory in macs\nsetwd(\"/Users/accountName/Desktop/BISemWeb2025/Day 1\")\n\nThis should set the working directory. Now, let us learn how to import a CSV data into RStudio.\n\n\n2.4 How do we import a CSV data in RStudio?\nAs you will be working mostly with comma separated value formatted data (i.e., csv) we will therefore learn how to import and export in RStudio. There are three files (1 CSV, 2 shapefiles) that we are going to import into RStudio:\n\nCIV_Sub_Prefecture_Mosquito_Data.csv which contains four columns about mosquito (i.e., Anopheles Gambiae) populations after insecticide campaign in Cote d’Ivoire across 113 sub-prefectures - NAME_3 (the name of sub-prefecture); TOTAL_MOSQ (total number of mosquitoes), TOTAL_MOSQ_DEATH (total number of mosquitoes that died after exposure to the insecticide), TOTAL_MOSQ_SURV (total number of mosquitoes that survived after exposure to the insecticide) and MORTALITY_ADJ_AVR (mortality adjusted rate).\nCIV_District.shp which is a vector layer containing the spatial boundaries of the 14 districts in Cote d’Ivoire.\nCIV_Sub_Prefectures.shp which is a vector layer containing the spatial boundaries of the 113 sub-prefectures in Cote d’Ivoire.\n\nTo import a csv into RStudio, we use the read.csv() function. To demonstrate this, let us import the data for fires into an data frame object and name it as CIV_Agg_Insect_ADMIN3\n\n# Import data using read.csv() function \nCIV_Agg_Insect_ADMIN3 &lt;- read.csv(file = \"CIV_Sub_Prefecture_Mosquito_Data.csv\", header = TRUE, sep = \",\")\n\n\n\n\n\n\n\nImportant\n\n\n\nThe arguments used in read.csv() function – 1.) ‘file =’ is a mandatory option where you quote the name of the file to be imported; 2.) ‘header = TRUE’ option is set to TRUE which is telling RStudio that the file that is about to be imported has column names on the first row so it should not treat as observations; and 3.) ‘sep = \",\"’ we are telling RStudio that the format of the dataset is comma separated.\n\n\nWe have imported the mosquito data. You can actually view the spreadsheet in the data viewer window using the code View():\n\n# Show viewer the data set\nView(CIV_Agg_Insect_ADMIN3)\n\n\n\n2.5 How do we import a shapefile into RStudio?\n\n2.5.1 Installing packages into RStudio\nSo far, we have been using functions and commands that are by default native or built-in RStudio. As you will become more and more proficient in RStudio, you will come to realise that there are several functions in RStudio that are in fact not built-in by default which will require external installation.\nFor instance, the sf package which is called Simply Features allows the user to load shapefiles (a type of Vector spatial data) into RStudio’s memory. Another important package is called tmap, this package gives access to various functions that allows the user to write code and emulate RStudio as a GIS software. These are examples of packages with enables mapping of spatial data. They need to be installed as they not built-in programs in RStudio.\nLet us install following packages: tmap and sf using the install.packages() function, and then initiate the packages to make them active in RStudio using the library() function.\nFirst sf and tmap packages:\n\ninstall.packages(\"sf\")\ninstall.packages(\"tmap\")\n\nOnce the installation is complete, you MUST activate the packages using the library() function. Type the following to perform this action:\n\n# Active the sf and tmap packages\nlibrary(\"sf\")\nlibrary(\"tmap\")\n\n\n\n2.5.2 Using the read_sf() to import shapefiles in RStudio\nThe sf package grants the user access to a function called read_sf() to read-in shapefiles into RStudio. A shapefile typically contains the geometry of the spatial features e.g., points, line segment and boundaries of an areal feature etc. The shapefile has the extension of .shp (and it is always accompanied by its other supporting files with extensions .shx, .prj, .dbf and .cpg).\n\n\n\n\n\n\nWarning\n\n\n\nThe following files must all be stored in the same folder location with the .shp file (i.e., .shx, .prj, .dbf and .cpg). If one is missing - the .shp file will not work!\n\n\nRecall, we have two shapefiles:\n\nCIV_District.shp for the districts\nCIV_Sub_Prefectures.shp for the sub-prefectures.\n\nWe can easily load them in RStudio as Spatial Polygon objects, type into your script:\n\n# Add shapefiles\nCIV_ADMIN1 &lt;- read_sf(\"CIV_District.shp\")\nCIV_ADMIN3 &lt;- read_sf(\"CIV_Sub_Prefectures.shp\")\n\n\n\n2.5.3 Joining two datasets by merger using the merge() function\nYou will often find yourself merging two or more data frames together, especially bringing together a spatial object with a non-spatial object. We cannot stress the importance of merging objects in the correct order so that the spatial attributes are preserved.\nIn this instance, we are just dealing with non-spatial dataset - i.e., the object CIV_Agg_Insect_ADMIN3 because while it contain the prefecture names it does not contain the geometry of those areas.\nHowever, the object CIV_ADMIN3 is a spatial dataset - as it contains the geometries that define the polygons of sub-prefecture areas (see image).\n\n\n\n\n\n\n\n\n\nYou can also check this by using the View() function on CIV_ADMIN3:\n\nView(CIV_ADMIN3)\n\nWe need merge these two objects CIV_ADMIN3 & CIV_Agg_Insect_ADMIN3using the merge() function. Consequently, we want the format of the merge code to look something akin to this syntax merge(target_object, selected_object, by=\"NAME_OF_LINK_COLUMN\").\nMerging data frames is indeed a very important technique to know especially if you need to bring together event information with no spatial dimension with actual spatial data for it to be mappable.\nAlright, let’s merge the mosquito data using the NAME_3 column with the shapefile dataset:\n\n# Merge the non-spatial table with ADMIN3 data frame\nCIV_Spatial_Data &lt;- merge(CIV_ADMIN3, CIV_Agg_Insect_ADMIN3, by.x = \"NAME_3\", by.y = \"NAME_3\", all.x = TRUE)\n# View the datasets\nView(CIV_Spatial_Data)\n\n\n\n\n\n\n\nImportant\n\n\n\nThe arguments used in merge.csv():\n\nCIV_ADMIN3 is the target data frame we want something to be merged on to.\nCIV_Agg_Insect_ADMIN3 is the selected data frame we are using to merge with the CIV_ADMIN3.\nby.x = \"NAME_3\" option we are specifying the name of the join column from the target data frame i.e., CIV_ADMIN3.\nby.y = \"NAME_3\" option we are specifying the name of the join column from the selected data frame i.e., CIV_Agg_Insect_ADMIN3\nall.x=TRUE option we are telling RStudio to retain all rows that are originally from the target data after merging regardless of whether or not they are present in the selected data frame. So even if a row from the selected data does not find a unique link with any of the rows in the target data to match - it will still preserve the target data frame by not discarding unlinked rows. But it will discard the unmatched rows from the selected data frame.",
    "crumbs": [
      "Practical Sessions",
      "Day 1: Basic Mapping in R"
    ]
  },
  {
    "objectID": "03-introduction_to_tmap.html#basic-visualisation-of-spatial-data-in-rstudio",
    "href": "03-introduction_to_tmap.html#basic-visualisation-of-spatial-data-in-rstudio",
    "title": "Day 1: Basic Mapping in R",
    "section": "3 Basic visualisation of spatial data in RStudio",
    "text": "3 Basic visualisation of spatial data in RStudio\n\n3.1 Mapping with ‘tmap’ functions in RStudio\nThe tmap is the best package for creating maps in RStudio – it’s easy to code and user friendly. Let’s finally start some mapping! Here are some basic ‘tmap’ functions to be very familiar with:\n\n\n\n\n\n\n\ntmap functions\nWhat it does…\n\n\n\n\ntm_shape()\nThis allows the user to add layers to be mapped\n\n\ntm_polygons()\nThis deal with vector type dataset specifically. This allows the user to specify which column in the vector layer to be mapped using the fill = argument. Within the tm_polygon(), it also allows the user to apply the appropriate customisation to the vector layer. Examples of such arguments in 1.) fill_alpha = to modify the transparency; 2.) col_alpha = to modify the transparency of the borders; 3.) col = controls the colour of the line; 4.) fill.scale = controls the appearence and set the colour scheme of the scale that appears inside the legends block. Please note that if your data is continuous, then the appropriate argument to use in the fill.scale = would be either tm_scale_continuous() or tm_scale_interval() for breaking the continuous values into intervals. If they are numerical but discrete (counts) use tm_scale_discrete(). Otherwise, if it is categorical use tm_scale_categorical(); and 4.) fill.legend = tm_legend(...) allows the user to control the presentation of the legend. There are many arguments to experiment with - you can type ?tm_polygons() in console to see them. Please note that the tm_polygons() is immediately followed after specifying the tm_shape() function.\n\n\ntm_layout()\nThis allows the user to make heavy customisations to the main title, legends and other cosmetics to text sizes etc.\n\n\ntm_compass()\nThis allows the user to add a compass visual to the map output\n\n\ntm_scale_bar()\nThis allows the user to add a scale bar to the map output\n\n\n\n\n3.1.1 Visualising the outline(s) of study area\nSuppose you want to visual just the outline of Cote d’Ivoire’s prefecture areas only:\n\n# Visual outline of prefecture only\ntm_shape(CIV_Spatial_Data) + tm_polygons()\n\nWe use the function tm_shape() and insert the CIV_Spatial_Data spatial object into its function, since we are plotting polygons follow it up with the function tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the above example is applies no customisation to the map!\n\n\nYou can customise the level of transparency for both the area and borders by adding some arguments in the tm_polygon() [i.e., fill_alpha, and col_alpha which only take values between 0 (full transparency) to 1 (100% solid)]. fill_alpha controls the transparency of the areas, and col_alpha controls the transparency of the borders.\nFor example:\n\ntm_shape(CIV_Spatial_Data) + tm_polygons(fill_alpha = 0.1, col_alpha = 0.4)\n\n\n\n\n\n\n\n\n\n\n\n\n3.1.2 Adding another layer on top of study area\nSuppose you want to add another layer to show the regions (i.e., Districts) of Cote d’Ivoire for which the sub-prefecture areas reside in, you can use another tm_shape() in the code add that additional layer, the coding would be as follows:\n\n# Adding another layer\n\ntm_shape(CIV_Spatial_Data) + \n    tm_polygons(fill_alpha = 0.1, col_alpha = 0.4) +\ntm_shape(CIV_ADMIN1) +\n    tm_polygons(fill_alpha = 0, col_alpha = 1, col = \"black\", lwd = 2)\n\n# The background of the added layer (CIV_ADMIN1) has been rendered to full transparency with the fill_alpha set to 0 and it borders are fully solid using col_alpha set to 1 and col (colour) set to “black” to appear pronounced. In addition, we have thickened the line by using setting that controls the line thickness `lwd = 2` \n\n\n\n\n\n\n\n\n\n\n\n\n3.1.3 Full visualising of data in the maps\nSuppose you want to visualise the spatial data in sub-prefectures, we can use the tm_polygons() function to specify the column of interest. For instance, let us visual the MORTALITY_ADJ_AVR column which has CONTINUOUS (or proportion) values ranging from 0 to 1 to signify areas that successfully reduced the treat of mosquito populations through insecticide application (with 1 equivalent to 100% mortality of mosquitoes after being exposed to the insecticide) and vice versa (with 0 meaning that all mosquitoes survived indicating resistance to this insecticide).\nThe coding would be as follows:\n\n# full visualisation\ntm_shape(CIV_Spatial_Data) + \n    tm_polygons(\n        fill = \"MORTALITY_ADJ_AVR\",\n        fill.scale = tm_scale_continuous(values = \"brewer.rd_yl_bu\"),\n        fill.legend = tm_legend(title = \"Mortality of Mosquitoes after inserticide [%]\", frame = FALSE, position = tm_pos_out()),\n        fill_alpha = 1, col_alpha = 0.5, col = \"black\", lwd = 0.5) +\ntm_shape(CIV_ADMIN1) + tm_text(\"NAME_1\") +\n    tm_polygons(fill_alpha = 0, col_alpha = 1, col = \"black\", lwd = 2) +\ntm_compass(type = \"arrow\", position = c(\"right\", \"top\")) +\ntm_scalebar(position = c(\"right\", \"bottom\"))\n\nIn the tm_polygons(), we insert the variable of interest we want to visual at the fill = argument. The fill.scale = option allows us to select the appropriate fill scale colour scheme depending on the type of dataset we are using - here it is continuous, so we use tm_scale_continuous(). The fill_legend() allows us to apply the appropriate customisation to the legends in the legend block.\nYou can also check all the available list of colour schemes by typing the code: cols4all::c4a_palettes().\n\n\n\n\n\n\nNote\n\n\n\nGeography 101 – when creating a map, it is always best to add the North compass and scale bar. This is done with the tm_compass() and tm_scalebar() functions. The tm_layout() allows you to make further customisations to the internal and external plot region of map such as turning of the plot frame or modifying the text size in output. You can experiment with them by checking the help menu – just type: ?tm_layout() in the console.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2 Generating interactive maps\nBy running the code: tmap_mode(\"view\"), will cause all map outputs to be generated in interactivity mode.\n\ntmap_mode(\"view\")\n\nThis should switch the plot from being static to something that is now dynamic. If we run code to generate the full map again, it will be displayed as an interactive map:\n\ntm_shape(CIV_Spatial_Data) + \n    tm_polygons(\n        fill = \"MORTALITY_ADJ_AVR\",\n        fill.scale = tm_scale_continuous(values = \"brewer.rd_yl_bu\"),\n        fill.legend = tm_legend(title = \"Mortality of Mosquitoes after inserticide [%]\", frame = FALSE, position = tm_pos_out()),\n        fill_alpha = 1, col_alpha = 0.5, col = \"black\", lwd = 0.5) +\ntm_shape(CIV_ADMIN1) + tm_text(\"NAME_1\") +\n    tm_polygons(fill_alpha = 0, col_alpha = 1, col = \"black\", lwd = 2) +\ntm_compass(type = \"arrow\", position = c(\"right\", \"top\")) +\ntm_scalebar(position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nYou can switch it off by running the following code: tmap_mode(\"plot\") to revert it back to static mode.\n\ntmap_mode(\"plot\")\n\nThis concludes Day 1’s session. On Day 2, we will use same the dataset to see if there is any patterns of clustering on where mosquitoes thrive despite being exposed to insecticides.",
    "crumbs": [
      "Practical Sessions",
      "Day 1: Basic Mapping in R"
    ]
  },
  {
    "objectID": "03-introduction_to_tmap.html#data-sources",
    "href": "03-introduction_to_tmap.html#data-sources",
    "title": "Day 1: Basic Mapping in R",
    "section": "4 Data Sources",
    "text": "4 Data Sources\n\nMalaria Threat Map (see: “Vector Insecticide Resistance”)[Source: World Health Organisation (WHO)] Click Here\nShapefiles for Cote d’Ivoire [Source: Database of Global Adminstrative Areas (GADM)] Click Here",
    "crumbs": [
      "Practical Sessions",
      "Day 1: Basic Mapping in R"
    ]
  },
  {
    "objectID": "04-morans_global_local.html",
    "href": "04-morans_global_local.html",
    "title": "Day 2: Detecting Clusters",
    "section": "",
    "text": "The goal of this session will focus on the key principle of spatial data - spatial dependence. Spatial dependence is the idea that the observed value of a variable in one location is often dependent (to some degree) on the observed value of the “somewhat” same value in a nearby location. For spatial analysis, this dependence can be assessed and measured statistically by considering the level of spatial autocorrelation between values of a specific variable, observed in either different locations or between pairs of variables observed at the same location. Spatial autocorrelation occurs when these values are not independent of one another and instead cluster together across geographic space.\nA critical first step of spatial autocorrelation is to define the criteria under which a spatial unit (e.g. an areal or point unit) can be understood as a “neighbour” to another unit. As highlighted in Day 1’s lecture, spatial properties can often take on several meanings (autocorrelation through neighbours, distance decay or spillovers), and as a result, have an impact on the validity and accuracy of spatial analysis. This multiplicity also can be applied to the concept of spatial neighbours which can be defined through adjacency, contiguity or distance-based measures. As the specification of these criteria can impact the results, the definition followed therefore need to be grounded in particular theory that aims to represent the process and variable investigated.\n\n\nUnderstanding the notion that spatial dependence refers to the degree of spatial autocorrelation between independently measured values observed in geographical space. We will learn how to estimate global measures of spatial autocorrelation (e.g., Moran’s I) to provide a singular measure of spatial dependence. We will learn how Local indicators of spatial association (LISA) to perform a similar function but yield multiple location-specific measures of spatial dependence.\n\n\n\nTo enable the efficient, repeatable and reproducible functionality of our work, we will use R-Studio’s ability to create and host code as a script. Before we do anything therefore, we will need to create a new R script: File &gt; New File &gt; R Script. Remember, you can save your script with the quick save shortcuts (e.g. cmd + s (mac) / ctrl + s (windows)).\n\n\n\nBefore you begin, if you have not done so already, please make sure to download all data by clicking here. Create a sub folder called “BISemWeb2025” within your “BISemWeb202” folder stored in the desktop of your personal computer. Make sure to extract all data from the downloaded zip folder and store it into “Day 2” folder. Use your newly open R script and set the work directory to Day 2’s folder.\nFor Windows, the code for setting the work directory will be:\n\nsetwd(\"C:/Users/accountName/Desktop/BISemWeb2025/Day 2\")\n\nFor MAC, the code for setting the work directory will be:\n\nsetwd(\"/Users/accountName/Desktop/BISemWeb2025/Day 2\")\n\n\n\n\nWe will need to load the following packages from the previous practicals:\n\nsf: Simple Features\ntmap: Thematic Mapping\n\nThe above packages sf and tmap should have been installed previously in the last session. Therefore, we do not have to install them again, we only need to activate them using the library() function. There will be some new packages we need to install:\n\nspdep: Provides access to a collection of functions to create spatial weights matrix objects from polygon contiguities, and testing spatial dependence\nsp: Provides access to a collection of functions for handling different classes and methods for spatial data\n\n\n# install the packages using the install.package()\ninstall.packages(\"spdep\")\ninstall.packages(\"sp\")\n\n# Load the packages with library()\nlibrary(\"sf\")\nlibrary(\"tmap\")\nlibrary(\"spdep\")\nlibrary(\"sp\")",
    "crumbs": [
      "Practical Sessions",
      "Day 2: Detecting Clusters"
    ]
  },
  {
    "objectID": "04-morans_global_local.html#introduction",
    "href": "04-morans_global_local.html#introduction",
    "title": "Day 2: Detecting Clusters",
    "section": "",
    "text": "The goal of this session will focus on the key principle of spatial data - spatial dependence. Spatial dependence is the idea that the observed value of a variable in one location is often dependent (to some degree) on the observed value of the “somewhat” same value in a nearby location. For spatial analysis, this dependence can be assessed and measured statistically by considering the level of spatial autocorrelation between values of a specific variable, observed in either different locations or between pairs of variables observed at the same location. Spatial autocorrelation occurs when these values are not independent of one another and instead cluster together across geographic space.\nA critical first step of spatial autocorrelation is to define the criteria under which a spatial unit (e.g. an areal or point unit) can be understood as a “neighbour” to another unit. As highlighted in Day 1’s lecture, spatial properties can often take on several meanings (autocorrelation through neighbours, distance decay or spillovers), and as a result, have an impact on the validity and accuracy of spatial analysis. This multiplicity also can be applied to the concept of spatial neighbours which can be defined through adjacency, contiguity or distance-based measures. As the specification of these criteria can impact the results, the definition followed therefore need to be grounded in particular theory that aims to represent the process and variable investigated.\n\n\nUnderstanding the notion that spatial dependence refers to the degree of spatial autocorrelation between independently measured values observed in geographical space. We will learn how to estimate global measures of spatial autocorrelation (e.g., Moran’s I) to provide a singular measure of spatial dependence. We will learn how Local indicators of spatial association (LISA) to perform a similar function but yield multiple location-specific measures of spatial dependence.\n\n\n\nTo enable the efficient, repeatable and reproducible functionality of our work, we will use R-Studio’s ability to create and host code as a script. Before we do anything therefore, we will need to create a new R script: File &gt; New File &gt; R Script. Remember, you can save your script with the quick save shortcuts (e.g. cmd + s (mac) / ctrl + s (windows)).\n\n\n\nBefore you begin, if you have not done so already, please make sure to download all data by clicking here. Create a sub folder called “BISemWeb2025” within your “BISemWeb202” folder stored in the desktop of your personal computer. Make sure to extract all data from the downloaded zip folder and store it into “Day 2” folder. Use your newly open R script and set the work directory to Day 2’s folder.\nFor Windows, the code for setting the work directory will be:\n\nsetwd(\"C:/Users/accountName/Desktop/BISemWeb2025/Day 2\")\n\nFor MAC, the code for setting the work directory will be:\n\nsetwd(\"/Users/accountName/Desktop/BISemWeb2025/Day 2\")\n\n\n\n\nWe will need to load the following packages from the previous practicals:\n\nsf: Simple Features\ntmap: Thematic Mapping\n\nThe above packages sf and tmap should have been installed previously in the last session. Therefore, we do not have to install them again, we only need to activate them using the library() function. There will be some new packages we need to install:\n\nspdep: Provides access to a collection of functions to create spatial weights matrix objects from polygon contiguities, and testing spatial dependence\nsp: Provides access to a collection of functions for handling different classes and methods for spatial data\n\n\n# install the packages using the install.package()\ninstall.packages(\"spdep\")\ninstall.packages(\"sp\")\n\n# Load the packages with library()\nlibrary(\"sf\")\nlibrary(\"tmap\")\nlibrary(\"spdep\")\nlibrary(\"sp\")",
    "crumbs": [
      "Practical Sessions",
      "Day 2: Detecting Clusters"
    ]
  },
  {
    "objectID": "04-morans_global_local.html#case-study-neglected-tropical-disease-ntd-distribution-in-cote-divoire",
    "href": "04-morans_global_local.html#case-study-neglected-tropical-disease-ntd-distribution-in-cote-divoire",
    "title": "Day 2: Detecting Clusters",
    "section": "2 Case study: Neglected Tropical Disease (NTD) Distribution in Cote d’Ivoire",
    "text": "2 Case study: Neglected Tropical Disease (NTD) Distribution in Cote d’Ivoire\nThis session looks at spatial dependence and autocorrelation in detail, focusing on the different methods of assessment. As part of this, we look at how to define spatial neighbours, and how this approach is used to generate spatial weights for use within these spatial autocorrelation methods as well as their potential to generate spatially-explicit variables.\nWe put these learnings into practice through an analysis of spatial dependence of areal neglected tropical disease data from World Health Organization’s Expanded Special Project for Elimination of Neglected Tropical Diseases (ESPEN), experimenting as an application for detecting clusters of diseases in Cote d’Ivoire. For this practical, we will look at the distribution of NTDs at community-level (level 4) in Cote d’Ivoire.\n\n2.1 Loading our data sets\nThere are three files (2 shapefiles) that we are going to import into RStudio:\n\nCIV_NTD_Community_ADMIN4.shp has been pre-prepared. It is a community-level shapefile containing 193 areas. It contains seven columns - NAME_3 (the name of the community); NAME_1 (the name of the district); examined (total number of people surveyed for NTD), positive (total number of people who were positive for an NTD); NTD_prev (estimated prevalence of NTD in a community); NTD_status (defines the endemic status of a community i.e., 1 = “Negligible (&lt;1%)”, 2 = “Low (1-10%)”, 3 = “Medium (10-30%)”, 4 = “High (30-50%)” and 5 = “Extreme (50%+)”); and lastly, PrefID (identifier for areas).\nCIV_District.shp which is a vector layer containing the spatial boundaries of the 14 districts in Cote d’Ivoire.\n\nLet’s load these shapefiles:\n\n# load two boundaries\nCIV_ADMIN1 &lt;- read_sf(\"CIV_District.shp\")\nCIV_Agg_NTD_ADMIN4 &lt;- read_sf(\"CIV_NTD_Community_ADMIN4.shp\")\n\nLet us fully display a map of the endemic status of NTDs in Cote d’Ivoire:\n\ntm_shape(CIV_Agg_NTD_ADMIN4) + \n    tm_polygons(\n        fill = \"NTD_status\",\n        fill.scale = tm_scale_categorical(values = c(\"white\", \"#74add1\", \"#ffffbf\", \"#fee08b\", \"#f46d43\"), \n            labels = c(\"Negligible (&lt;1%)\", \"Low (1-10%)\", \"Medium (10-30%)\", \"High (30-50%)\", \"Extreme (50%+)\")),\n        fill.legend = tm_legend(title = \"NTD Infection Status\", frame = FALSE, position = tm_pos_out()),\n        fill_alpha = 1, col_alpha = 0.5, col = \"black\", lwd = 0.5) +\n    tm_shape(CIV_ADMIN1) + tm_text(\"NAME_1\") +\n    tm_polygons(fill_alpha = 0, col_alpha = 1, col = \"black\", lwd = 2) +\n    tm_compass(type = \"arrow\", position = c(\"right\", \"top\")) +\n    tm_scalebar(position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nInterpretation: You can see how some of these areas have the same extreme endemicity status of general NTD infection. At face-value, these patterns seem to cluster in neighbouring communities within next-to-door districts such as Denguele, Savanes and Woroba, as well as Yamoussoukro and Lacs.\n\n\nLet us proceed to test whether these are actual areas for where such NTD disease outcomes are concentrated at.\n\n\n2.2 Global Moran’s I\nWith a Global Moran’s I, we can test how “random” the spatial distribution of these values is. Global Moran’s I is a metric between -1 and 1. -1 is a completely even spatial distribution of values, 0 is a “random” distribution, and 1 is a “non-random” distribution of clearly defined clusters.\nTo calculate the Global Moran’s I, you need an adjacency matrix that contains the information of whether or not an community area in Cote d’Ivoire is next to another. Because of the way Moran’s I functions in R, it is necessary to use the sp and spdep libraries (which we have installed and loaded earlier). As you will see these methods and functions have quite esoteric and complicated syntax. Some of the operations they will do will be similar to the examples shown earlier, but the way they assign and store variables makes it much quicker to run complex spatial operations.\nWe start by understand the spatial configuration of the study area, simply by view what the area’s ID number is - trust me on this - you will need this visual to do sanity checks!\n\n# see spatial configuration of areas\ntm_shape(CIV_Agg_NTD_ADMIN4) + \n    tm_polygons(fill = \"white\") + tm_text(\"PrefID\", size = 0.7)\n\n\n\n\n\n\n\n\n\n\nNow, we can make an adjacency matrix adjacency_matrix_community object in which we store for each OA which other OAs are considered to be neighbours.\n\n# create adjacency matrix\nadjacency_matrix_community &lt;- poly2nb(CIV_Agg_NTD_ADMIN4)\n# sanity checks - ensure all is in alignment\nnames(adjacency_matrix_community) &lt;- CIV_Agg_NTD_ADMIN4$NAME_4\n# check first 10 neighbourhoods, and cross-check with map to examine it the neighbours are right!\nhead(adjacency_matrix_community, n = 10)\n\n\n##$Abengourou\n##[1]   8  10  13  16  23  48  64 132 188\n\n##$`Abidjan-Ville`\n##[1]  12  26  83 163\n\n##$Aboisso\n##[1]   4  16  34 123\n\n##$Adiake\n##[1]   3  34 123 172\n\n##$Adzope\n##[1]   6   7   9  10  11 188\n\n##$Affery\n##[1]   5   7  10  31 120\n\n##$Agboville\n##[1]   5   6   9  17 120 143 158 163 173\n\n##$Agnibilekro\n##[1]   1  64 114 132\n\n##$Agou\n##[1]  5  7 11 17\n\n##$Akoupe\n##[1]   1   5   6  13  31 188\n\nThis shows the first 10 neighbourhoods in the list, and which neighbourhoods are sharing borders. You can cross-check the information with the map to ensure that the adjacency matrix is in order. This is just for sanity-checks!\nNext, we need to assign weights to each neighbouring polygons formed around a community. In our case, each neighbouring polygon will be assigned equal weight with style='W'. After this, we can calculate a value for the Global Moran’s I.\n\n# global Moran's I test\nmoran.test(CIV_Agg_NTD_ADMIN4$positive, community_weights_list)\n\n\n##  Moran I test under randomisation\n\n##data:  CIV_Agg_NTD_ADMIN4$positive  \n##weights: community_weights_list    \n\n##Moran I statistic standard deviate = 7.5212, p-value = 2.714e-14\n##alternative hypothesis: greater\n##sample estimates:\n##Moran I statistic       Expectation          Variance \n##      0.319104147      -0.005208333       0.001859321 \n\nThe Global Moran’s I seems to indicate that there is indeed some spatial autocorrelation in our data, however, this is just a quick way to check the score. To do so properly we need to compare our score a randomly distributed version of the variables. We can do this by using something called a Monte Carlo simulation.\n\n# run a Monte Carlo simulation 599 times\nmoran.mc(CIV_Agg_NTD_ADMIN4$positive, community_weights_list, nsim=1000)\n\n\n##  Monte-Carlo simulation of Moran I\n\n##data:  CIV_Agg_NTD_ADMIN4$positive \n##weights: community_weights_list  \n##number of simulations + 1: 1001 \n\n##statistic = 0.3191, observed rank = 1001, p-value = 0.000999\n##alternative hypothesis: greater\n\nThis model shows that our distribution of NTDs differs significantly from a random distribution. As such, we can conclude that there is significant spatial autocorrelation in our NTD data set.\n\n\n2.3 Local Moran’s I (or LISA)\nWith a measurement of local spatial autocorrelation we could find hotspots of theft that are surrounded by areas of much lower NTDs. According to the previous global statistic these are not randomly distributed pockets but would be outliers against the general trend of clusteredness! These could be areas that contain very specific locations, where interventions could be made that drastically reduce the rate of disease rather than other areas where there is a high level of ambient disease.\n\n# local Moran's I test\nlocal_moran_CIV_NTD &lt;- localmoran(CIV_Agg_NTD_ADMIN4$positive, community_weights_list)\n\nRemember in the lecture the following conditions:\n\n\n\n\n\n\n\n\n\nTo properly utilise these local statistics and make an intuitively useful map, we need to combine them with our disease positive count variable. Because of the way the new variable will be calculated, we first need to rescale our variable so that the mean is 0.\n\n# rescale\nCIV_Agg_NTD_ADMIN4$scale_positive &lt;- scale(CIV_Agg_NTD_ADMIN4$positive)\n\nTo compare this rescaled value against its neighbours, we subsequently need to create a new column that carries information about the neighbours. This is called a spatial lag function. The “lag” just refers to the fact you are comparing one observation against another, this can also be used between timed observations. In this case, the “lag” we are looking at is between neighbours.\n\n# create a spatial lag variable \nCIV_Agg_NTD_ADMIN4$scale_lag_positive &lt;- lag.listw(community_weights_list, CIV_Agg_NTD_ADMIN4$scale_positive)\n\nTo make a human readable version of the map we will generate some labels for our findings from the Local Moran’s I stats. This process calculates what the value of each polygon is compared to its neighbours and works out if they are similar or dissimilar and in which way, then gives them a text label to describe the relationship.\n\n# MAP 1: VERSION WITH FULL CLUSTER HH, HL, LH, LL DETAILS\n# classification without significance value\nCIV_Agg_NTD_ADMIN4$ClusterID &lt;- NA\nCIV_Agg_NTD_ADMIN4$ClusterID[CIV_Agg_NTD_ADMIN4$scale_positive &gt; 0 & CIV_Agg_NTD_ADMIN4$scale_lag_positive &gt; 0] &lt;- 1\nCIV_Agg_NTD_ADMIN4$ClusterID[CIV_Agg_NTD_ADMIN4$scale_positive &gt; 0 & CIV_Agg_NTD_ADMIN4$scale_lag_positive &lt; 0] &lt;- 2\nCIV_Agg_NTD_ADMIN4$ClusterID[CIV_Agg_NTD_ADMIN4$scale_positive &lt; 0 & CIV_Agg_NTD_ADMIN4$scale_lag_positive &gt; 0] &lt;- 3\nCIV_Agg_NTD_ADMIN4$ClusterID[CIV_Agg_NTD_ADMIN4$scale_positive &lt; 0 & CIV_Agg_NTD_ADMIN4$scale_lag_positive &lt; 0] &lt;- 4\n\nNow let’s see how the clusters are arranged spatially.\n\n# MAP 1\ntm_shape(CIV_Agg_NTD_ADMIN4) + \n    tm_polygons(\n        fill = \"ClusterID\",\n        fill.scale = tm_scale_categorical(values = c(\"#f46d43\", \"#fee0d2\", \"#deebf7\", \"#3182bd\"), \n            labels = c(\"HH\", \"HL\", \"LH\", \"LL\")),\n        fill.legend = tm_legend(title = \"NTD Cluster Map\", frame = FALSE, position = tm_pos_out()),\n        fill_alpha = 1, col_alpha = 0.5, col = \"black\", lwd = 0.5) +\n    tm_shape(CIV_ADMIN1) + tm_text(\"NAME_1\") +\n    tm_polygons(fill_alpha = 0, col_alpha = 1, col = \"black\", lwd = 2) +\n    tm_compass(type = \"arrow\", position = c(\"right\", \"top\")) +\n    tm_scalebar(position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nInterpretation: You can see how some of the areas that had extreme endemic status of NTD infection being classed as High-High cluster in most parts of Denguele and Lacs, as well as small pockets of communities in Savanes and Sassandra-Marahoue and Lagunes.\n\n\nLet us now find which of these clusters are statistically significant, we create a final label to define clusters that are significant based on the p-value 0.05:\n\n# MAP 2: VERSION WITH SIGNIFICANCE\n# create indicator for cluster map with statistical significance\nCIV_Agg_NTD_ADMIN4$Sig_ID &lt;- NA\nCIV_Agg_NTD_ADMIN4$Sig_ID[CIV_Agg_NTD_ADMIN4$scale_positive &gt; 0 & CIV_Agg_NTD_ADMIN4$scale_lag_positive &gt; 0 & local_moran_CIV_NTD[,5] &lt; 0.05] &lt;- 1\nCIV_Agg_NTD_ADMIN4$Sig_ID[CIV_Agg_NTD_ADMIN4$scale_positive &gt; 0 & CIV_Agg_NTD_ADMIN4$scale_lag_positive &lt; 0 & local_moran_CIV_NTD[,5] &lt; 0.05] &lt;- 2\nCIV_Agg_NTD_ADMIN4$Sig_ID[CIV_Agg_NTD_ADMIN4$scale_positive &lt; 0 & CIV_Agg_NTD_ADMIN4$scale_lag_positive &gt; 0 & local_moran_CIV_NTD[,5] &lt; 0.05] &lt;- 3\nCIV_Agg_NTD_ADMIN4$Sig_ID[CIV_Agg_NTD_ADMIN4$scale_positive &lt; 0 & CIV_Agg_NTD_ADMIN4$scale_lag_positive &lt; 0 & local_moran_CIV_NTD[,5] &lt; 0.05] &lt;- 4\nCIV_Agg_NTD_ADMIN4$Sig_ID[local_moran_CIV_NTD[,5] &gt;= 0.05] &lt;- 5\n# note what was categorised\ntable(CIV_Agg_NTD_ADMIN4$Sig_ID)\n\nNow let’s see how the significant clusters are arranged spatially.\n\n# MAP 2\ntm_shape(CIV_Agg_NTD_ADMIN4) + \n    tm_polygons(\n        fill = \"Sig_ID\",\n        fill.scale = tm_scale_categorical(values = c(\"#f46d43\", \"#deebf7\", \"white\"), \n            labels = c(\"HH\", \"LH\", \"Not Significant\")),\n        fill.legend = tm_legend(title = \"NTD Cluster Map: Significance\", frame = FALSE, position = tm_pos_out()),\n        fill_alpha = 1, col_alpha = 0.5, col = \"black\", lwd = 0.5) +\n    tm_shape(CIV_ADMIN1) + tm_text(\"NAME_1\") +\n    tm_polygons(fill_alpha = 0, col_alpha = 1, col = \"black\", lwd = 2) +\n    tm_compass(type = \"arrow\", position = c(\"right\", \"top\")) +\n    tm_scalebar(position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nInterpretation: You can see that the areas with extreme endemic status of NTD infection in Lacs are statistically significant as High-High cluster, meaning that this disease pattern is not due by chance. There are few community areas that surround these significant High-High locations, which are significant Low-High meaning that they have the potential to transition to High-High cluster. Public health authorities, based on the evidence, should look into these areas in Lacs",
    "crumbs": [
      "Practical Sessions",
      "Day 2: Detecting Clusters"
    ]
  },
  {
    "objectID": "04-morans_global_local.html#data-sources",
    "href": "04-morans_global_local.html#data-sources",
    "title": "Day 2: Detecting Clusters",
    "section": "3 Data Sources",
    "text": "3 Data Sources\n\nExpanded Special Project for Elimination of Neglected Tropical Diseases (ESPEN)[Source: World Health Organisation (WHO)] Click Here\nShapefiles for Cote d’Ivoire [Source: Database of Global Adminstrative Areas (GADM)] Click Here",
    "crumbs": [
      "Practical Sessions",
      "Day 2: Detecting Clusters"
    ]
  },
  {
    "objectID": "01-installation.html",
    "href": "01-installation.html",
    "title": "Installation",
    "section": "",
    "text": "R (or RStudio) is a statistical programming package that allows users to carry out a wide range of statistical analyses. It can also function as GIS software, enabling various types of analysis on geographical data. In the same way, it can be used for data management and geoprocessing—for example, importing different types of data, whether non-spatial or spatial, and preparing them for analysis.\nThere are two versions:\n\n\n\n\n\n\n\n\n\nThe famous icon on the left is the version for R (Base), and the one on the right is the version for RStudio. Both software packages are the same. The only difference is that RStudio is attractive, intuitive, and more importantly, it is user-friendly than Base R. So, we will be using this version (i.e., RStudio) throughout this workshop.\nLet us talk about the installation of RStudio on your personal computer.\n\n\nRStudio is an open-source software, it is free. It is widely recommended in data science, scientific research, and technical communication because it is easy to access, download, and install. To use RStudio, you must first install R (Base) before installing RStudio as it serves as an engine to RStudio. Follow the steps below to install both programs for your operating system (Windows or Mac).\nSteps\n\nDownload the R (Base) installer from the table below, then run the file to complete the installation. If you are a Windows user, you must download Rtools before proceeding to step 2.\nNext, download the RStudio installer from the table below, then run the file to complete the installation.\n\n\n\n\nOS User type\nDownloadable Software Packages\n\n\n\n\nWindows 10/11\n[1] R (4.5.2); [2] RTools (4.5); [3] RStudio (2025.09.2-418)\n\n\nMacOS 13+ (Intel)\n[1] R (4.5.2); [2] RStudio (2025.09.2-418);\n\n\nMacOS 13+ (M1/M2/M3/M4)\n[1] R (4.5.2); [2] RStudio (2025.09.2-418)\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nR (Base) is very particular about the operating system! Please be sure to use the correct installer for your computer:\n\nWindows users: use the files in the first row.\nMac (Intel) users: use the files in the second row.\nMac (M1, M2, M3 or M4 chip) users: use the files in the third row.\n\n\n\nThis section covers how to download and install RStudio for it to be used locally on your machine. Now, you are ready to participate in tomorrows computer practical session.",
    "crumbs": [
      "Getting Started",
      "Installation"
    ]
  },
  {
    "objectID": "01-installation.html#download-and-installation-of-software",
    "href": "01-installation.html#download-and-installation-of-software",
    "title": "Installation",
    "section": "",
    "text": "RStudio is an open-source software, it is free. It is widely recommended in data science, scientific research, and technical communication because it is easy to access, download, and install. To use RStudio, you must first install R (Base) before installing RStudio as it serves as an engine to RStudio. Follow the steps below to install both programs for your operating system (Windows or Mac).\nSteps\n\nDownload the R (Base) installer from the table below, then run the file to complete the installation. If you are a Windows user, you must download Rtools before proceeding to step 2.\nNext, download the RStudio installer from the table below, then run the file to complete the installation.\n\n\n\n\nOS User type\nDownloadable Software Packages\n\n\n\n\nWindows 10/11\n[1] R (4.5.2); [2] RTools (4.5); [3] RStudio (2025.09.2-418)\n\n\nMacOS 13+ (Intel)\n[1] R (4.5.2); [2] RStudio (2025.09.2-418);\n\n\nMacOS 13+ (M1/M2/M3/M4)\n[1] R (4.5.2); [2] RStudio (2025.09.2-418)\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nR (Base) is very particular about the operating system! Please be sure to use the correct installer for your computer:\n\nWindows users: use the files in the first row.\nMac (Intel) users: use the files in the second row.\nMac (M1, M2, M3 or M4 chip) users: use the files in the third row.\n\n\n\nThis section covers how to download and install RStudio for it to be used locally on your machine. Now, you are ready to participate in tomorrows computer practical session.",
    "crumbs": [
      "Getting Started",
      "Installation"
    ]
  },
  {
    "objectID": "00-index.html",
    "href": "00-index.html",
    "title": "BISemWeb2025",
    "section": "",
    "text": "Welcome to the 2-day practical session hosted at BISemWeb 2025 @ ENSEA (Abidjan, Cote d’Ivoire). Part of this computer practical session is to deliver an interactive training session on Introductory Spatial Data Analysis in RStudio for basic mapping for any particular indicators in Cote d’Ivoire. We will be using mosquito insecticide treatment dataset from the World Health Organisation (WHO) to build intuition on the programming & data handling aspects in RStudio.\nThis training session has been designed purely as an introduction to show the core programming tenets for basic spatial analysis in RStudio. This online resource is free of charge, and thus has been designed as reference to this session and will remain available indefinitely to participants.\n\n\nAll lectures and computer practicals will be delivered hybrid. The table below contains the lessons and learning materials:\n\n\n\nDay\nSession\nTopics\n\n\n\n\n17/12/2025\nLecture\nIntro. Spatial Data Analysis [Slides]\n\n\n18/12/2025\nPractical I\nBasic mapping using tmap [Dataset]\n\n\n19/12/2025\nPractical II\nSpatial Autocorrelation [Dataset]\n\n\n\n\nIMPORTANT NOTE: If you can, please bring your own laptops with you to participate in these remote sessions. These will be recorded accordingly and the associated video will be made available.\n\n\n\n\nBeyond the course, please feel free to contact me via email for help, or if you would like a Zoom meeting for additional support if need be.\nMy contact information is:\n\n\n\nName\nEmail\n\n\n\n\nDr. Anwar Musah\na.musah@ucl.ac.uk",
    "crumbs": [
      "Overview",
      "Welcome"
    ]
  },
  {
    "objectID": "00-index.html#structure",
    "href": "00-index.html#structure",
    "title": "BISemWeb2025",
    "section": "",
    "text": "All lectures and computer practicals will be delivered hybrid. The table below contains the lessons and learning materials:\n\n\n\nDay\nSession\nTopics\n\n\n\n\n17/12/2025\nLecture\nIntro. Spatial Data Analysis [Slides]\n\n\n18/12/2025\nPractical I\nBasic mapping using tmap [Dataset]\n\n\n19/12/2025\nPractical II\nSpatial Autocorrelation [Dataset]\n\n\n\n\nIMPORTANT NOTE: If you can, please bring your own laptops with you to participate in these remote sessions. These will be recorded accordingly and the associated video will be made available.",
    "crumbs": [
      "Overview",
      "Welcome"
    ]
  },
  {
    "objectID": "00-index.html#contact-details-of-instructor",
    "href": "00-index.html#contact-details-of-instructor",
    "title": "BISemWeb2025",
    "section": "",
    "text": "Beyond the course, please feel free to contact me via email for help, or if you would like a Zoom meeting for additional support if need be.\nMy contact information is:\n\n\n\nName\nEmail\n\n\n\n\nDr. Anwar Musah\na.musah@ucl.ac.uk",
    "crumbs": [
      "Overview",
      "Welcome"
    ]
  },
  {
    "objectID": "02-reading_list.html",
    "href": "02-reading_list.html",
    "title": "Reading Materials",
    "section": "",
    "text": "These are excellent books for studying spatial data analysis more broadly to gain mastery of the theory and coding execution. You can access their PDF versions HERE.",
    "crumbs": [
      "Getting Started",
      "Reading Materials"
    ]
  }
]